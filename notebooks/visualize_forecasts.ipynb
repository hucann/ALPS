{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to results directory\n",
    "RESULTS_DIR = '../results/forecasts/run_20250528_152237'  \n",
    "# RESULTS_DIR = 'models_test'\n",
    "\n",
    "# Load all model directories\n",
    "model_dirs = [d for d in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, d))]\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# Load and combine metrics\n",
    "for model_name in model_dirs:\n",
    "    metrics_path = os.path.join(RESULTS_DIR, model_name, 'metrics_summary.csv')\n",
    "    if os.path.exists(metrics_path):\n",
    "        df = pd.read_csv(metrics_path)\n",
    "        df['model'] = model_name\n",
    "        all_metrics.append(df)\n",
    "\n",
    "metrics_df = pd.concat(all_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison Table (Averaged over all products):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mape",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3f6395ee-2cc5-49c9-ad0f-e6fda6c13e8b",
       "rows": [
        [
         "2",
         "NaiveMovingAverage",
         "46.97465979914533",
         "0.18965329695012914"
        ],
        [
         "6",
         "TCNModel",
         "48.32635235",
         "0.1848588245"
        ],
        [
         "5",
         "RandomForest",
         "48.87271988246313",
         "0.1868685302048528"
        ],
        [
         "1",
         "NBEATSModel",
         "53.46652635",
         "0.20291115450000002"
        ],
        [
         "3",
         "Prophet",
         "53.95940814848135",
         "0.21821262611712466"
        ],
        [
         "4",
         "RNNModel",
         "57.949172399999995",
         "0.2368271865"
        ],
        [
         "0",
         "ARIMA",
         "62.9534403501891",
         "0.2590143093409457"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveMovingAverage</td>\n",
       "      <td>46.974660</td>\n",
       "      <td>0.189653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TCNModel</td>\n",
       "      <td>48.326352</td>\n",
       "      <td>0.184859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>48.872720</td>\n",
       "      <td>0.186869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBEATSModel</td>\n",
       "      <td>53.466526</td>\n",
       "      <td>0.202911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>53.959408</td>\n",
       "      <td>0.218213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNNModel</td>\n",
       "      <td>57.949172</td>\n",
       "      <td>0.236827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>62.953440</td>\n",
       "      <td>0.259014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model       mape      rmse\n",
       "2  NaiveMovingAverage  46.974660  0.189653\n",
       "6            TCNModel  48.326352  0.184859\n",
       "5        RandomForest  48.872720  0.186869\n",
       "1         NBEATSModel  53.466526  0.202911\n",
       "3             Prophet  53.959408  0.218213\n",
       "4            RNNModel  57.949172  0.236827\n",
       "0               ARIMA  62.953440  0.259014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary table: average metrics per model\n",
    "summary_df = metrics_df.groupby('model').agg({'mape': 'mean', 'rmse': 'mean'}).reset_index()\n",
    "summary_df = summary_df.sort_values(by='mape')\n",
    "\n",
    "print(\"\\nüìä Model Comparison Table (Averaged over all products):\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Forecast Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Interactive Forecast Plot ===\n",
    "def plot_forecast_vs_truth(model_name, product_id):\n",
    "    forecast_path = os.path.join(RESULTS_DIR, model_name, f'forecast_product_{product_id}.csv')\n",
    "    truth_path = os.path.join(RESULTS_DIR, model_name, f'ground_truth_product_{product_id}.csv')\n",
    "\n",
    "    if not os.path.exists(forecast_path) or not os.path.exists(truth_path):\n",
    "        print(f\"‚ùå No forecast or ground truth data for model {model_name} product {product_id}\")\n",
    "        return\n",
    "\n",
    "    forecast_df = pd.read_csv(forecast_path, index_col=0, parse_dates=True)\n",
    "    truth_df = pd.read_csv(truth_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(truth_df, label='Ground Truth', color='blue')\n",
    "    plt.plot(forecast_df, label='Forecast', color='orange')\n",
    "    plt.title(f'{model_name} - Product {product_id} Forecast vs. Ground Truth')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Units Sold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e900d2fb984c5b9b9b94c122ab5cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', options=('ARIMA', 'TCNModel', 'RandomForest', 'Prophet', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selector = widgets.Dropdown(options=model_dirs, description='Model:')\n",
    "product_selector = widgets.IntSlider(value=0, min=0, max=10, step=1, description='Product ID:')  # adjust max as needed\n",
    "\n",
    "interactive_plot = widgets.interact(plot_forecast_vs_truth, model_name=model_selector, product_id=product_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

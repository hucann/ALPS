{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to results directory\n",
    "RESULTS_DIR = '../results/forecasts/run_20250528_165923'  \n",
    "# RESULTS_DIR = 'models_test'\n",
    "\n",
    "# Load all model directories\n",
    "model_dirs = [d for d in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, d))]\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# Load and combine metrics\n",
    "for model_name in model_dirs:\n",
    "    metrics_path = os.path.join(RESULTS_DIR, model_name, 'metrics_summary.csv')\n",
    "    if os.path.exists(metrics_path):\n",
    "        df = pd.read_csv(metrics_path)\n",
    "        df['model'] = model_name\n",
    "        all_metrics.append(df)\n",
    "\n",
    "metrics_df = pd.concat(all_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison Table (Averaged over all products):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mape",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "12c65329-bc0f-42c0-9b87-1114de785a36",
       "rows": [
        [
         "6",
         "TCNModel",
         "9.850886129023582",
         "0.2973964920545063"
        ],
        [
         "5",
         "RandomForest",
         "10.350251038745883",
         "0.3100795109319793"
        ],
        [
         "1",
         "NBEATSModel",
         "10.655496220171974",
         "0.3209996702671515"
        ],
        [
         "2",
         "NaiveMovingAverage",
         "12.743465056561316",
         "0.37012865189432925"
        ],
        [
         "4",
         "RNNModel",
         "13.45775443216029",
         "0.4158422614120479"
        ],
        [
         "3",
         "Prophet",
         "16.08293795174297",
         "0.4542142483089561"
        ],
        [
         "0",
         "ARIMA",
         "22.277039628648176",
         "0.6290248483888077"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mape</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TCNModel</td>\n",
       "      <td>9.850886</td>\n",
       "      <td>0.297396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>10.350251</td>\n",
       "      <td>0.310080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBEATSModel</td>\n",
       "      <td>10.655496</td>\n",
       "      <td>0.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveMovingAverage</td>\n",
       "      <td>12.743465</td>\n",
       "      <td>0.370129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNNModel</td>\n",
       "      <td>13.457754</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>16.082938</td>\n",
       "      <td>0.454214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>22.277040</td>\n",
       "      <td>0.629025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model       mape      rmse\n",
       "6            TCNModel   9.850886  0.297396\n",
       "5        RandomForest  10.350251  0.310080\n",
       "1         NBEATSModel  10.655496  0.321000\n",
       "2  NaiveMovingAverage  12.743465  0.370129\n",
       "4            RNNModel  13.457754  0.415842\n",
       "3             Prophet  16.082938  0.454214\n",
       "0               ARIMA  22.277040  0.629025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary table: average metrics per model\n",
    "summary_df = metrics_df.groupby('model').agg({'mape': 'mean', 'rmse': 'mean'}).reset_index()\n",
    "summary_df = summary_df.sort_values(by='mape')\n",
    "\n",
    "print(\"\\nüìä Model Comparison Table (Averaged over all products):\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Forecast Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Interactive Forecast Plot ===\n",
    "def plot_forecast_vs_truth(model_name, product_id):\n",
    "    forecast_path = os.path.join(RESULTS_DIR, model_name, f'forecast_product_{product_id}.csv')\n",
    "    truth_path = os.path.join(RESULTS_DIR, model_name, f'ground_truth_product_{product_id}.csv')\n",
    "\n",
    "    if not os.path.exists(forecast_path) or not os.path.exists(truth_path):\n",
    "        print(f\"‚ùå No forecast or ground truth data for model {model_name} product {product_id}\")\n",
    "        return\n",
    "\n",
    "    forecast_df = pd.read_csv(forecast_path, index_col=0, parse_dates=True)\n",
    "    truth_df = pd.read_csv(truth_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(truth_df, label='Ground Truth', color='blue')\n",
    "    plt.plot(forecast_df, label='Forecast', color='orange')\n",
    "    plt.title(f'{model_name} - Product {product_id} Forecast vs. Ground Truth')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Units Sold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9eb428b370436c9874bee00f6bb565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', options=('ARIMA', 'TCNModel', 'RandomForest', 'Prophet', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selector = widgets.Dropdown(options=model_dirs, description='Model:')\n",
    "product_selector = widgets.IntSlider(value=0, min=0, max=10, step=1, description='Product ID:')  # adjust max as needed\n",
    "\n",
    "interactive_plot = widgets.interact(plot_forecast_vs_truth, model_name=model_selector, product_id=product_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
